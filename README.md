# Implicit Hate Speech Detection Model

## Project Overview

This project aims to create an unbiased and diversified dataset for an implicit hate speech detection model. We use Google's Perspective API and Jigsaw's Detoxify library to compare their scores on various attributes.

## Dataset Creation

The dataset is created by collecting data from various sources to ensure diversity and reduce bias. The data is then processed and labeled for use in the model.

## Tools Used

- **Google's Perspective API**: This tool helps us to score the comments based on their toxicity levels. It uses machine learning models to score the perceived impact a comment might have on a conversation.

- **Jigsaw's Detoxify Library**: This library provides pre-trained models for toxic comment classification. It helps us to understand the severity and type of toxicity for each comment.

## Model

The implicit hate speech detection model is trained on the created dataset. The model aims to accurately classify implicit hate speech in various forms of text.

## Evaluation

The model's performance is evaluated using various metrics such as accuracy, precision, recall, and F1-score. The scores from Google's Perspective API and Jigsaw's Detoxify library are also compared to understand their effectiveness in detecting implicit hate speech.

<!--
## Installation
## Usage

## Contributing

We welcome contributions to improve the dataset and the model. Please read the CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.
-->
